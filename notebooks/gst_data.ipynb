{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Import Required Libraries and Set Up Environment Variables\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Dependencies\n",
				"import os\n",
				"import pandas as pd\n",
				"from dotenv import load_dotenv\n",
				"from datetime import datetime\n",
				"\n",
				"# project service file for housing python functions\n",
				"from services import services\n",
				"\n",
				"## Load the NASA_API_KEY from the env file\n",
				"load_dotenv()\n",
				"NASA_API_KEY = os.getenv(\"NASA_API_KEY\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": []
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### GST Data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Set the base URL to NASA's DONKI API:\n",
				"base_url = \"https://api.nasa.gov/DONKI/\"\n",
				"\n",
				"# Set the specifier for Geomagnetic Storms (GST):\n",
				"GST = \"GST\"\n",
				"\n",
				"# Search for GSTs between a begin and end date\n",
				"startDate = \"2013-05-01\"\n",
				"endDate = \"2024-05-01\"\n",
				"\n",
				"# Build URL for GST\n",
				"query_url = (\n",
				"    f\"{base_url}{GST}?startDate={startDate}&endDate={endDate}&api_key={NASA_API_KEY}\"\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Convert the response variable to json and store it as a variable named gst_json\n",
				"# Preview the first result in JSON format\n",
				"# Use json.dumps with argument indent=4 to format data\n",
				"gst_json = services.fetch_data(query_url, {}, True)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"print(gst_json)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Convert gst_json to a Pandas DataFrame\n",
				"df = pd.DataFrame(gst_json)\n",
				"\n",
				"# Keep only the columns: activityID, startTime, linkedEvents\n",
				"df = df[[\"gstID\", \"startTime\", \"linkedEvents\"]]\n",
				"df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Notice that the linkedEvents column allows us to identify the corresponding CME\n",
				"# Remove rows with missing 'linkedEvents' since we won't be able to assign these to CME\n",
				"df = df.dropna(how=\"any\")\n",
				"df.isna().sum()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Notice that the linkedEvents sometimes contains multiple events per row\n",
				"# Use the explode method to ensure that each row is one element. Ensure to reset the index and drop missing values.\n",
				"# Initialize an empty list to store the expanded rows\n",
				"expanded_rows = services.expand_rows(df)\n",
				"print(expanded_rows)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Apply the extract_activityID_from_dict function to each row in the 'linkedEvents' column (you can use apply() and a lambda function)\n",
				"# and create a new column called 'CME_ActivityID' using loc indexer:\n",
				"df[\"GST_ActivityID\"] = df.linkedEvents.apply(\n",
				"    lambda x: services.extract_activityID_from_dict(x)\n",
				")\n",
				"\n",
				"# Remove rows with missing CME_ActivityID, since we can't assign them to CMEs:\n",
				"df.sample(n=5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Convert the 'CME_ActivityID' column to string format\n",
				"# Convert the 'cmeID' column to string format\n",
				"# Convert startTime to datetime format\n",
				"# Rename startTime to startTime_CME\n",
				"# Drop linkedEvents\n",
				"# Verify that all steps were executed correctly\n",
				"clean_df = services.clean_up(df, \"gst\")\n",
				"clean_df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# We are only interested in GSTs related to CMEs so keep only rows where the CME_ActivityID column contains 'CME'\n",
				"# use the method 'contains()' from the str library.\n",
				"gst_to_cme_events = clean_df[clean_df.GST_ActivityID.str.contains(\"CME\")]\n",
				"\n",
				"for event in gst_to_cme_events.GST_ActivityID:\n",
				"    print(event)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3 (ipykernel)",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.12.2"
		},
		"varInspector": {
			"cols": {
				"lenName": 16,
				"lenType": 16,
				"lenVar": 40
			},
			"kernels_config": {
				"python": {
					"delete_cmd_postfix": "",
					"delete_cmd_prefix": "del ",
					"library": "var_list.py",
					"varRefreshCmd": "print(var_dic_list())"
				},
				"r": {
					"delete_cmd_postfix": ") ",
					"delete_cmd_prefix": "rm(",
					"library": "var_list.r",
					"varRefreshCmd": "cat(var_dic_list()) "
				}
			},
			"types_to_exclude": [
				"module",
				"function",
				"builtin_function_or_method",
				"instance",
				"_Feature"
			],
			"window_display": false
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
